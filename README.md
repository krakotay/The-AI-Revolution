# The-AI-Revolution
Перевод на русский статьи https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html

Original article by Tim Urban, Wait But Why: https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html  
© Tim Urban (All rights reserved).  
Translation © 2025 krakotay.


Примечание: Причина, по которой этот пост занял три недели, в том, что, когда я начал изучать тему искусственного интеллекта, я не мог поверить в то, что читал. Довольно быстро меня поразило осознание, что происходящее в мире ИИ — это не просто важная тема, а безусловно САМАЯ важная тема для нашего будущего. Поэтому я захотел узнать о ней как можно больше, а когда разобрался, то захотел написать пост, который действительно объясняет всю ситуацию и почему это так важно. Неудивительно, что в итоге он получился безумно длинным, поэтому я разбил его на две части. Это — Часть 1, Часть 2 находится [здесь](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html). 

«Мы на пороге перемен, сопоставимых с возникновением человеческой жизни на Земле». — Вернор Виндж (Vernor Vinge)

Какого это - быть здесь?

![image](https://github.com/user-attachments/assets/2f4bcaf5-a3e1-4fe3-adc2-c3e4bdbf8868)

Кажется, что стоять в такой точке — довольно напряжённо. Но потом нужно вспомнить одну особенность стояния на временной шкале: ты не можешь видеть, что находится справа. Так вот, вот как это *на самом деле* ощущается, когда ты стоишь там:

![image](https://github.com/user-attachments/assets/78426c57-8ba1-4584-b455-838be8050b07)

Что, вероятно, кажется таким обычным...

--- 

# Будущее на пороге

Представь, что ты сел в машину времени и отправился в 1750 год — во времена, когда мир находился в состоянии постоянного блэкаута, дальняя связь означала либо орать изо всех сил, либо стрелять из пушки в небо, а всё передвижение зависело от сена. Ты попадаешь туда, хватаешь чувака, приносишь его в 2015 год и водишь по миру, наблюдая за его реакцией на всё происходящее.

Нам с тобой просто невозможно по-настоящему представить, что он будет чувствовать, увидев блестящие капсулы, мчащиеся по шоссе, поговорив с человеком, который утром был по ту сторону океана, посмотрев спортивный матч за тысячу миль от него, услышав музыкальное выступление, записанное 50 лет назад, и поиграв с моим волшебным прямоугольником, с помощью которого можно захватить изображение реального мира или записать живой момент, вызвать карту с паранормальной синей точкой, показывающей, где он находится, посмотреть на лицо человека и поговорить с ним, даже если тот на другом конце страны — и это ещё до того, как ты покажешь ему интернет или расскажешь о таких вещах, как Международная космическая станция, Большой адронный коллайдер, ядерное оружие или общая теория относительности.

Для него всё это было бы не просто удивительно или шокирующе, и даже не «взрыв мозга» — эти слова слишком слабы. Он, возможно, буквально бы умер.

Но вот что интересно — если бы он вернулся обратно в 1750 год, немного позавидовал нам, что мы увидели его реакцию, и решил сделать то же самое, он бы взял машину времени и отправился примерно в 1500 год, захватил бы оттуда кого-нибудь, притащил его в 1750-й и показал бы ему всё. Человек из 1500-го был бы шокирован многими вещами — но он бы не умер. Это был бы куда менее безумный опыт, потому что, хотя 1500-й и 1750-й годы сильно отличались, между ними всё-таки не такая гигантская разница, как между 1750 и 2015. Человек из 1500-го узнал бы кучу мозговзрывающих штук про космос и физику, был бы впечатлён тем, насколько Европа серьёзно отнеслась к моде на империализм, и ему пришлось бы серьёзно пересмотреть своё представление о карте мира. Но просто наблюдать повседневную жизнь 1750 года — транспорт, связь и т.д. — явно не убило бы его.

Нет, чтобы чуваку из 1750-го года было *так же весело*, как нам с ним, ему пришлось бы отмотать намного дальше — возможно, аж в 12 000 год до н.э., до Первой аграрной революции, которая дала начало первым городам и самому понятию цивилизации. Если бы кто-то из чисто охотничье-собирательного мира — из времени, когда люди были, по сути, просто ещё один вид животных — увидел огромные человеческие империи 1750 года с их возвышающимися церквями, кораблями, пересекающими океаны, понятием «находиться *внутри*» и гигантской горой накопленных знаний и открытий — он бы, скорее всего, умер.

А теперь представь, что он умер, позавидовал, и тоже захотел повторить фокус. Он бы отмотал на 12 000 лет назад — в 24 000 год до н.э. — схватил бы кого-нибудь и притащил в 12 000 год до н.э., чтобы показать ему всё. А тот посмотрел бы и сказал: «Ну и что, какая разница?» Чтобы человек из 12 000 до н.э. испытал такую же встряску, ему нужно было бы вернуться больше чем на 100 000 лет назад и показать кому-то впервые огонь и речь.

Чтобы перемещение в будущее вызвало настолько сильный шок, что человек просто умер бы от перегруза, должно пройти достаточно лет, чтобы произошёл скачок, достойный смерти от прогресса — так называемая «единица прогресса до смерти» или **DPU** (Die Progress Unit). В эпоху охотников-собирателей на одну DPU уходило свыше 100 000 лет, но после аграрной революции хватало уже 12 000 лет. А после индустриальной революции прогресс пошёл настолько быстро, что человеку из 1750 года нужно всего лишь переместиться на пару сотен лет вперёд — и всё, DPU достигнута.

Эта закономерность — ускоряющееся движение человеческого прогресса со временем — это то, что футуролог Рэй Курцвейл называет *Законом ускоряющейся отдачи* (Law of Accelerating Returns) в истории человечества. Она объясняется тем, что более развитые общества способны прогрессировать быстрее, чем менее развитые — просто потому что они более развиты. Люди XIX века знали больше и обладали лучшими технологиями, чем люди XV века, так что неудивительно, что в XIX веке человечество сделало гораздо больше открытий, чем в XV — люди XV века просто не могли конкурировать с людьми XIX.

Это работает и в меньших масштабах. Фильм *Назад в будущее* вышел в 1985 году, а «прошлое» в нём — это 1955 год. Когда герой Майкла Джей Фокса попадает в 1955-й, его удивляют "новизна" телевизоров, копеечные цены на газировку, нелюбовь к пронзительной электрогитаре и смена сленга. Да, это был другой мир — но если бы фильм снимали сегодня, и «прошлое» в нём было бы 1985-м, различия были бы куда более яркими и интересными. Персонаж оказался бы в эпохе до персональных компьютеров, интернета и мобильных телефонов — современный Марти МакФлай, подросток конца 90-х годов рождения, чувствовал бы себя в 1985-м куда более неуместно, чем оригинальный Марти в 1955-м.

**Это по той же причине, о которой мы только что говорили — Закон Ускоряющейся Отдачи (Law of Accelerating Returns).** Средний темп прогресса между 1985 и 2015 годами был выше, чем между 1955 и 1985 — потому что мир в 1985 уже был более продвинутым. Поэтому за последние 30 лет произошло гораздо больше изменений, чем за предыдущие 30.

То есть — прогресс становится всё более масштабным и происходит всё быстрее. Это наводит на весьма мощные мысли о нашем будущем, не так ли?

Рэй Курцвейл утверждает, что прогресс всего XX века можно было бы достичь всего за 20 лет, если бы он происходил с той скоростью, что была в 2000 году. Иными словами, к 2000 году скорость прогресса была в **пять раз выше**, чем средняя скорость за весь XX век. Он считает, что ещё один «вековой объём» прогресса произошёл между 2000 и 2014 годами, и что следующий такой объём произойдёт до 2021 года — всего за 7 лет. А ещё через пару десятилетий, по его мнению, эквивалент века прогресса будет происходить **по нескольку раз в год**, а затем — **менее чем за месяц**. В целом, из-за Закона Ускоряющейся Отдачи, Курцвейл считает, что XXI век принесёт **в 1000 раз больше прогресса**, чем XX[^2].

Если Курцвейл и те, кто с ним согласен, правы, то **мы будем в таком же шоке от 2030 года, как человек из 1750 был бы от 2015 года**. То есть следующий «скачок развития» может занять всего пару десятилетий — и мир 2050 года может быть настолько другим, что мы его едва ли узнаем.

Это не научная фантастика. Это то, во что твёрдо верят многие учёные, более умные и информированные, чем ты или я. И если посмотреть на историю, это именно то, чего следовало бы **логически ожидать**.

Так почему же, когда я говорю что-то вроде «через 35 лет мир может быть абсолютно неузнаваемым», ты думаешь: «Круто… но неееее»?

Вот три причины, почему мы скептически относимся к таким дерзким прогнозам будущего:

**1. Когда речь заходит об истории, мы думаем линейно.** Представляя себе прогресс следующих 30 лет, мы смотрим на прогресс предыдущих 30 как на ориентир того, сколько всего может произойти. Когда мы размышляем о том, насколько изменится мир в XXI веке, мы просто прибавляем прогресс XX века к 2000 году. Это та же ошибка, которую допустил наш парень из 1750 года, когда взял человека из 1500 года и ожидал, что тот удивится так же сильно, как он сам был потрясён, пройдя ту же дистанцию вперёд. Нам интуитивно проще думать линейно, хотя на самом деле нужно думать экспоненциально. Если кто-то подходит к этому с большей хитростью, он может попытаться предсказать достижения следующих 30 лет не по предыдущим 30, а исходя из текущего темпа прогресса. Это будет точнее, но всё равно сильно мимо. Чтобы правильно представить будущее, нужно вообразить, что всё будет развиваться гораздо быстрее, чем сейчас.

![image](https://github.com/user-attachments/assets/587df661-df6d-4c08-b8a6-27afaecd0d48)

**2. Траектория самой недавней истории часто искажает картину.** Во-первых, даже крутая экспоненциальная кривая выглядит как прямая, если рассматривать только её маленький участок — так же, как небольшой сегмент огромного круга вблизи кажется почти прямой линией. Во-вторых, экспоненциальный рост не бывает полностью плавным и равномерным. Курцвейл объясняет, что прогресс происходит по «S-образным кривым»:


![image](https://github.com/user-attachments/assets/7f38d138-1a19-4154-94a1-9428547ee814)
S-образная кривая формируется волной прогресса, когда новый парадигмальный сдвиг охватывает мир. Кривая проходит через три фазы:

1. Медленный рост (ранняя фаза экспоненциального роста)  
2. Быстрый рост (поздняя, взрывная фаза экспоненциального роста)  
3. Замедление, когда конкретная парадигма достигает зрелости [^3]

Если смотреть только на самую недавнюю историю, тот участок S-кривой, на котором мы находимся в данный момент, может исказить наше восприятие того, насколько быстро всё развивается. Отрезок времени между 1995 и 2007 годами ознаменовался взрывным ростом интернета, появлением Microsoft, Google и Facebook в массовом сознании, рождением социальных сетей и внедрением сначала мобильных телефонов, а затем и смартфонов. Это была Фаза 2: период бурного роста на S-кривой. Но 2008–2015 годы были менее революционными, по крайней мере в технологическом плане. Человек, размышляющий сегодня о будущем, может опереться на последние несколько лет, чтобы оценить темп прогресса — но тем самым он упускает из виду всю картину. На самом деле, вполне возможно, что новая, масштабная Фаза 2 — прямо сейчас зреет.

**3) Наш личный опыт делает нас упрямыми стариками по отношению к будущему.** Мы формируем представления о мире на основе собственного опыта, и этот опыт внедрил в наше сознание темп роста последнего времени как "естественный порядок вещей". Мы также ограничены нашим воображением, которое строит прогнозы, исходя из пройденного опыта — но часто того, что мы знаем, просто недостаточно, чтобы точно представить будущее[^4]. Когда мы слышим прогноз, который противоречит нашему опыту, интуиция говорит нам: "Это наивно". Если я скажу тебе чуть позже в этом тексте, что ты можешь прожить до 150, 250 лет или вообще не умереть, твоя первая реакция будет: "Это бред — если история чему-то и учит, так это тому, что умирают все". И да, в прошлом никто не избежал смерти. Но и самолёты никто не изобретал — до тех пор, пока не изобрёл.

Так что, хотя "неееее" может казаться правильной реакцией, на самом деле она, скорее всего, ошибочна. Факт в том, что если быть действительно логичным и ожидать продолжения исторических закономерностей, то мы должны заключить, что в ближайшие десятилетия произойдёт **намного, намного, намного больше изменений**, чем мы интуитивно предполагаем. Логика также подсказывает, что если самая продвинутая форма жизни на планете продолжает делать всё более крупные скачки всё быстрее и быстрее, то рано или поздно произойдёт такой скачок, который полностью изменит само представление о жизни и о том, что значит быть человеком — примерно так же, как эволюция шла скачками к разуму, пока наконец не случился такой гигантский рывок, который привёл к появлению человека и изменил само понятие жизни на Земле. А если немного почитать о том, что сейчас происходит в науке и технологиях, становится видно: всё больше и больше признаков намекают на то, что жизнь в её нынешнем виде **не переживёт** следующий скачок.

# Путь к ASI
## Что такое ИИ?
Если ты такой же, как я, то раньше считал искусственный интеллект глупой фантастикой, но в последнее время начал слышать о нём от серьёзных людей — и всё ещё толком не понимаешь, о чём речь.

Есть три причины, почему термин "ИИ" сбивает с толку многих людей:

1) Мы ассоциируем ИИ с кино. *Звёздные войны*, *Терминатор*, *Космическая одиссея 2001 года*, *Джетсоны*. Всё это вымысел — и робот-персонажи тоже. Поэтому ИИ кажется нам чем-то вымышленным.

2) ИИ — это широкая тема. Он охватывает всё: от калькулятора в телефоне до беспилотных автомобилей и будущих технологий, способных радикально изменить мир. Всё это называют ИИ, и это сбивает с толку.

3) Мы постоянно используем ИИ в повседневной жизни, но часто не осознаём, что это именно он. Джон Маккарти, придумавший термин “искусственный интеллект” в 1956 году, жаловался, что “как только что-то начинает работать, это уже перестают называть ИИ”[^5]. Из-за этого ИИ часто воспринимается как мифическое предсказание будущего, а не как реальность. Одновременно он кажется поп-культурной идеей из прошлого, которая так и не реализовалась. Рэй Курцвейл говорит, что слышал от людей, будто ИИ "заглох" в 1980-х, и сравнивает это с утверждением, будто интернет "умер" во время краха доткомов в начале 2000-х[^6].

Так что давай проясним. Во-первых, перестань думать о роботах. Робот — это оболочка для ИИ, иногда в форме человека, иногда нет — но сам ИИ это компьютер внутри робота. ИИ — это мозг, а робот — его тело, если оно вообще есть. Например, программное обеспечение и данные за Siri — это ИИ; женский голос, который мы слышим, — это персонификация ИИ, и никакого робота тут нет.

Во-вторых, ты, возможно, слышал термин “сингулярность” или “технологическая сингулярность”. В математике этот термин описывает ситуацию, похожую на асимптоту, где перестают действовать обычные правила. В физике он используется для описания феноменов вроде чёрных дыр или точки, в которой вся материя была сжата перед Большим взрывом. Снова — ситуации, где привычные правила перестают работать. В 1993 году Вернор Виндж написал [знаменитое эссе](https://edoras.sdsu.edu/~vinge/misc/singularity.html), в котором применил этот термин к моменту в будущем, когда интеллект технологий превзойдёт человеческий — моменту, после которого жизнь уже никогда не будет прежней. Рэй Курцвейл немного запутал термин, определив сингулярность как момент, когда Закон Ускоряющейся Отдачи достигнет такой скорости, что технологический прогресс станет практически бесконечным, и после этого мы окажемся в совершенно новом мире. Я обнаружил, что многие современные исследователи ИИ уже почти не используют этот термин — он и правда сбивает с толку — так что и я буду упоминать его нечасто (хотя сама идея будет основой всего излагаемого).

Наконец, хотя ИИ бывает разных типов и форм — потому что это очень широкое понятие — ключевое, на что стоит обращать внимание, это **уровень развития** ИИ. Существуют три основных уровня:

### AI Caliber 1: Artificial Narrow Intelligence (ANI)  
Также известный как “слабый ИИ”, это ИИ, который специализируется в одной конкретной области. Например, ИИ, способный обыграть чемпиона мира по шахматам, умеет **только** играть в шахматы. Попроси его придумать новый способ хранения данных на жёстком диске — он уставится на тебя в растерянности.

### AI Caliber 2: Artificial General Intelligence (AGI)  
Также известный как “сильный ИИ” или “ИИ человеческого уровня”. Это машина, которая может выполнять **любую интеллектуальную задачу**, доступную человеку. Создать AGI гораздо сложнее, чем ANI, и мы пока этого не сделали. Профессор Линда Готфредсон описывает интеллект как “очень общую умственную способность, которая, среди прочего, включает способность рассуждать, планировать, решать задачи, мыслить абстрактно, понимать сложные идеи, быстро учиться и извлекать уроки из опыта”. AGI должно уметь делать всё это так же легко, как и ты.

### AI Caliber 3: Artificial Superintelligence (ASI)  
Философ из Оксфорда и ведущий исследователь ИИ Ник Бостром определяет сверхинтеллект как “разум, который значительно умнее лучших человеческих умов практически во всех областях, включая научное творчество, мудрость и социальные навыки”. ASI может варьироваться от ИИ, немного превосходящего человека, до такого, что **в триллионы раз умнее** — по всем направлениям. Именно из-за ASI тема ИИ вызывает столько бурных обсуждений — и именно поэтому слова “бессмертие” и “вымирание” будут ещё не раз упомянуты в этом тексте.

На данный момент человечество покорило лишь самый нижний уровень — ANI — во множестве форм, и он повсюду. Революция ИИ — это путь от ANI к AGI, и затем к ASI — путь, который мы можем не пережить, но который в любом случае **изменит всё**.

Теперь давай внимательно рассмотрим, как этот путь выглядит в представлении ведущих экспертов — и почему эта революция может случиться **гораздо раньше**, чем ты думаешь:

# Где мы сейчас (2015 год): ANI

**Artificial Narrow Intelligence (ANI)** — это машинный интеллект, который равен или превосходит человеческий по эффективности в **одной конкретной задаче**. Вот несколько примеров:

- Автомобили полны ANI-систем — от компьютера, определяющего момент включения антиблокировочной системы тормозов, до компьютера, настраивающего параметры впрыска топлива. [Самоуправляемый автомобиль Google](https://youtu.be/aFbz00gnJtQ?si=_VPdM6B1z4dFKpZb), который проходит тестирование прямо сейчас, будет содержать мощные ANI-системы, позволяющие ему воспринимать и реагировать на мир вокруг.
- Ваш телефон — это маленькая фабрика ANI. Когда вы используете навигацию, получаете музыкальные рекомендации от Pandora, проверяете прогноз погоды, разговариваете с Siri — вы используете ANI.
- Спам-фильтр в электронной почте — классический пример ANI: он изначально оснащён знаниями о том, как отличать спам от нормальных писем, а затем обучается под ваши личные предпочтения. То же самое делает термостат Nest, запоминая ваш распорядок и подстраиваясь под него.
- Все эти жутковатые штуки, когда вы ищете товар на Amazon, а потом он появляется в “рекомендованных” на другом сайте, или когда Facebook вдруг знает, кого вам стоит добавить в друзья — это сеть ANI-систем. Они обмениваются данными, узнают о вас и решают, что вам показывать. То же касается и “Покупатели этого товара также приобрели…” — это ANI-система, которая анализирует поведение миллионов покупателей и пытается продать вам больше.
- Google Translate — ещё один классический ANI: впечатляюще хорош в одной узкой задаче. Распознавание речи — тоже ANI, и множество приложений совмещают их, позволяя произнести фразу на одном языке и получить её перевод на другом.
- Когда ваш самолёт приземляется, решение, к какому гейту он поедет, принимает не человек. И цену билета тоже рассчитывает не человек.
- Лучшие игроки в шашки, шахматы, скрэббл, нарды и отелло сегодня — ANI-системы.
- Google Search — это огромный ANI-мозг с невероятно сложной системой ранжирования страниц и персонализации. То же касается новостной ленты Facebook.
- И это только потребительская сфера. Сложные ANI-системы активно используются в армии, промышленности, финансах (алгоритмические трейдеры на основе ИИ совершают **более половины сделок с акциями на рынках США**[^7]), а также в экспертных системах, помогающих врачам ставить диагнозы — и, конечно, [в IBM Watson](http://www.ibm.com/smarterplanet/us/en/ibmwatson/), который настолько хорошо владел фактами и тонкостями формулировок ведущего "Jeopardy!", что разгромил чемпионов шоу.

На текущем этапе ANI не вызывает особого страха. В худшем случае плохо запрограммированная ANI-система может вызвать **локальную катастрофу** — отключение энергосистемы, сбой на АЭС или крах финансового рынка (как в случае с [Flash Crash 2010 года](https://ritholtz.com/wp-content/uploads/2010/10/flash-crash-dow-popup.png), когда ANI-программа неправильно отреагировала на нестандартную ситуацию, вызвав обрушение рынка и потерю $1 трлн рыночной стоимости, часть из которых потом восстановили).

Но даже если ANI не представляет экзистенциальной угрозы, мы должны понимать: этот всё более сложный и обширный **экосистемный фундамент** ANI — это **предвестник урагана**, который изменит весь мир. Каждая новая инновация ANI незаметно кладёт очередной кирпич на дороге к AGI и ASI. Или, как выразился [Аарон Саенц](https://singularityhub.com/2010/08/10/we-live-in-a-jungle-of-artificial-intelligence-that-will-spawn-sentience/), современные ANI-системы — это "как аминокислоты в первобытном бульоне ранней Земли" — неживые элементы будущей жизни, которые однажды вдруг проснулись.

# Путь к AGi
И почему он такой тяжёлый
Ничто так не заставит тебя ценить человеческий интеллект, как попытка создать компьютер, такой же умный, как мы. Построить небоскрёбы, отправить людей в космос, разобраться в деталях Большого взрыва — всё это **намного проще**, чем понять, как работает наш мозг, или тем более — создать что-то столь же крутое. На сегодняшний день **человеческий мозг — самый сложный объект во Вселенной**, который нам известен.

Интересно то, что **наиболее трудные аспекты создания AGI** (искусственного интеллекта, умного в целом, а не в одной узкой задаче) — это вовсе не те, какими они кажутся на первый взгляд.  
Сделать компьютер, который умножит два десятизначных числа за долю секунды? Легкотня.  
Сделать ИИ, который посмотрит на животное и скажет, собака это или кошка? Ужасно сложно.  
ИИ, который обыгрывает любого человека в шахматы? Уже есть.  
А вот заставить ИИ прочитать абзац из детской книжки и не просто распознать слова, а **понять их смысл** — [на это Google тратит миллиарды долларов прямо сейчас](https://www.wired.com/2014/01/google-buying-way-making-brain-irrelevant/).  
Сложные для нас вещи — вроде интегралов, биржевых стратегий или перевода языков — для компьютера **элементарны**, а "простые" вещи — зрение, движение, восприятие — **безумно трудны**.

Как выразился компьютерный учёный Дональд Кнут:  
> “ИИ уже преуспел почти во всём, что требует ‘мышления’, но пока не справляется с большинством вещей, которые люди и животные делают ‘не думая’”[^8].

И тут ты быстро осознаёшь: **то, что нам кажется лёгким, на самом деле безумно сложно**, и оно **кажется лёгким**, потому что в нас (и в животных) эти навыки оттачивались сотни миллионов лет эволюции.  
Когда ты тянешь руку к предмету, твои мышцы, сухожилия и кости плеча, локтя и запястья мгновенно выполняют сложнейшие физические расчёты, координируясь с глазами — чтобы рука пошла по нужной траектории в трёхмерном пространстве. Это кажется тебе лёгким, потому что в твоём мозгу установлено идеально отлаженное ПО, оттачившееся с рождения.

Вот почему не стоит считать вирус “тупым” за то, что он не может пройти капчу с кривыми буквами — наоборот, **твой мозг — гениален**, раз справляется с этим без усилий.

А теперь наоборот: умножение больших чисел или игра в шахматы — это **новые** виды деятельности для биологических существ. У нас **не было времени эволюционировать** для них, поэтому компьютеру не нужно прилагать больших усилий, чтобы нас превзойти.

Подумай: что бы ты предпочёл — написать программу, которая умножает большие числа, или программу, которая **понимает суть буквы “B”** настолько хорошо, что распознаёт её в **любой из тысяч случайных рукописей или шрифтов** — и мгновенно узнаёт: “да, это B”?

Один забавный пример — когда ты смотришь на это изображение, ты и компьютер оба можете определить, что это прямоугольник с чередующимися оттенками:
![image](https://github.com/user-attachments/assets/5b1d6645-16c6-4645-8e75-f82aaf5a8116)

Пока что — ничья. Но если ты поднимешь чёрную часть и откроешь всё изображение…

![image](https://github.com/user-attachments/assets/9013ef2e-3ebc-42e7-8079-9963cc6ba3dd)

…тебе **не составит труда** описать различные непрозрачные и полупрозрачные цилиндры, планки и объёмные углы, в то время как компьютер **с треском провалится**. Он опишет то, что действительно “видит” — набор двухмерных фигур в разных оттенках — и будет **буквально прав**.  

Но твой мозг тем временем делает кучу сложнейшей работы, чтобы интерпретировать **возможную глубину**, **смешение теней** и **освещение комнаты**, которое пытается передать изображение[^9].

А на следующей картинке — когда компьютер видит двухмерную бело-чёрно-серую мозаику, ты **мгновенно** распознаёшь, что это на самом деле — **фотография полностью чёрного объёмного камня**:

![image](https://github.com/user-attachments/assets/3b2e57cf-df2f-4b16-ba22-f766e1e564ab)

И всё, что мы только что упомянули, — это всё ещё просто восприятие застывшей информации и её обработка. Чтобы быть интеллектуально на уровне человека, компьютеру пришлось бы понимать такие вещи, как разницу между тонкими выражениями лица, различие между состояниями «доволен», «облегчён», «удовлетворён», «счастлив» и «рад», а также почему *Храброе сердце* — это великий фильм, а *Патриот* — ужасный.

Ужасает.

Так как же мы к этому придём?

## Первый ключ: рост вычислительной мощности


Одним из неотъемлемых условий, которые должны быть выполнены для возможности создания AGI (искусственный общий интеллект), является увеличение производительности компьютерного оборудования. Если система искусственного интеллекта должна быть настолько умной, как человеческий мозг, ей нужно будет соответствовать вычислительной мощности мозга.

Один из способов оценить эту мощность — это рассчитать общее количество операций в секунду (cps), которое может выполнять мозг. Для этого можно определить максимальную производительность каждой структуры мозга и сложить их все вместе.

Рэй Курцвейл предложил удобный способ: он брал профессиональную оценку производительности одной структуры мозга, учитывал её вес по сравнению с весом всего мозга и пропорционально экстраполировал, чтобы получить оценку общей производительности. Способ кажется несколько спорным, но Курцвейл провёл такие расчёты множество раз, используя различные профессиональные оценки разных регионов мозга, и каждый раз получал результат в одном и том же диапазоне — около 10¹⁶, или 10 квадрильонов cps.

Сейчас самый быстрый в мире суперкомпьютер, [«Тяньхэ-2»](https://www.reuters.com/article/2014/11/17/us-china-supercomputer-idUSKCN0J11VV20141117/) в Китае, уже превзошёл этот показатель, достигнув 34 квадрильонов cps. Однако «Тяньхэ-2» имеет свои недостатки: он занимает 720 квадратных метров пространства, потребляет 24 мегаватта электроэнергии (мозг работает всего на [20 ваттах](https://web.archive.org/web/20150211185811/http://www.popsci.com/technology/article/2009-11/neuron-computer-chips-could-overcome-power-limitations-digital)) и стоит 390 миллионов долларов. Это пока что неприменимо к широкому использованию, даже большинству коммерческих или промышленных нужд.

Курцвейл предлагает рассматривать развитие компьютеров через призму того, сколько cps можно купить за $1000. Когда эта цифра достигнет уровня человеческого мозга — 10 квадрильонов cps — это будет означать, что AGI может стать реальностью нашей жизни.

Закон Мура — исторически надёжное правило, согласно которому максимальная вычислительная мощность удваивается каждые два года. То есть развитие компьютерного оборудования, как и общая эволюция человека в истории, происходит экспоненциально. Рассматривая это применительно к метрике Курцвейла cps/$1000, мы сейчас имеем примерно 10 триллионов cps/$1000, что точно соответствует прогнозируемой траектории графика[^10]:

![image](https://github.com/user-attachments/assets/80435108-0482-49fa-bbee-3eee37f4a3eb)

Таким образом, компьютеры за $1000 уже превосходят мозг мыши и находятся на уровне примерно одной тысячной от человеческого. На первый взгляд это немного, но если вспомнить, что в 1985 году мы были на уровне одного триллионной части, в 1995 году — миллиардной, а в 2005 — миллионной, то оказывается, что достижение уровня в одну тысячную в 2015 году ставит нас прямо на путь к тому, чтобы к 2025 году иметь доступный компьютер, который будет конкурировать с мощностью мозга.

Таким образом, с точки зрения аппаратной части, необходимая для AGI вычислительная мощность технически доступна уже сейчас, в Китае, и мы будем готовы к доступному, массовому распространению оборудования уровня AGI в течение следующих 10 лет. Но сама по себе вычислительная мощность ещё не делает компьютер достаточно умным. Следующий вопрос: как привести уровень человеческого интеллекта к этой мощности?

# Второй ключ к созданию AGI: Сделать его умным

Это неприятная часть. Правда в том, что никто действительно не знает, как сделать его умным — мы до сих пор спорим о том, как создать компьютер, обладающий человеческим уровнем интеллекта и способный понять, что такое собака, странный написанный B или средненький фильм. Но есть несколько фантастических стратегий, и в какой-то момент одна из них сработает. Вот три наиболее распространенных стратегии, которые я встретил:

**1) Копировать мозг.**
Это похоже на то, как ученые долгие годы пытаются понять, почему тот ученик, который сидит рядом с ними в классе, так хорошо сдает экзамены, и даже когда они тщательно готовятся, они не могут сравняться с этим учеником, и в конце концов они решают: «Черт с ним, я просто скопирую его ответы». Это логично — мы застряли в попытках построить сверхсложный компьютер, а в наших головах уже есть идеальный прототип.

Наука активно работает над обратной инженерией мозга, чтобы понять, как эволюция создала такой отличный механизм — [оптимистичные оценки](https://www.wired.com/2010/08/reverse-engineering-brain-kurzweil/) говорят, что мы можем это сделать к 2030 году. Как только мы это сделаем, мы узнаем все секреты того, как мозг работает так мощно и эффективно, и сможем использовать его инновации. Пример компьютерной архитектуры, имитирующей мозг — искусственная нейронная сеть. Она начинается как сеть транзисторных «нейронов», соединённых между собой входами и выходами, и ничего не знает — как мозг новорожденного. То, как она «учится», заключается в том, что она пытается выполнить задачу, например, распознавание рукописного текста, и на первом этапе её нейронные импульсы и последующие предположения по расшифровке каждой буквы будут полностью случайными. Но когда ей говорят, что она права, связи в цепочках импульсов, которые привели к этому ответу, усиливаются; когда ей говорят, что она ошиблась, эти связи ослабляются. После многих таких испытаний и обратной связи сеть сама формирует умные нейронные пути, и машина становится оптимизированной для задачи. Мозг учится немного так же, но более изощренно, и по мере того, как мы продолжаем изучать мозг, мы открываем новые умные способы использования нейронных цепей.

Более крайний вариант плагиата включает в себя стратегию под названием «всестороннее моделирование мозга», где цель — разрезать реальный мозг на тонкие слои, сканировать каждый из них, использовать программное обеспечение для создания точной трёхмерной модели и затем реализовать модель на мощном компьютере. Тогда у нас будет компьютер, официально способный делать всё, что может сделать мозг — ему просто нужно будет учиться и собирать информацию. Если инженеры станут очень хорошими, они смогут смоделировать настоящий мозг с такой точностью, что личность и память мозга останутся целыми, когда архитектура мозга будет загружена на компьютер. Если мозг принадлежал Джиму непосредственно перед его смертью, компьютер теперь проснётся как Джим (?), что будет прочным человеческим уровнем АГИ, и мы сможем работать над тем, чтобы превратить Джима в невероятно умный АСИ, которое, вероятно, будет очень радо.

Насколько близки мы к достижению всестороннего моделирования мозга? Ну, пока мы ~~не смогли~~ [недавно смоделировали](https://www.smithsonianmag.com/smart-news/weve-put-worms-mind-lego-robot-body-180953399/?no-ist) мозг червя длиной 1 мм, состоящий всего из 302 нейронов. Мозг человека содержит 100 миллиардов. Если это кажется безнадёжным проектом, помните о силе экспоненциального прогресса — теперь, когда мы победили мозг червя, возможно, скоро мы сможем сделать это с муравьём, затем с мышью, и внезапно это станет намного более правдоподобным.

**2) Попробовать заставить эволюцию сделать то, что она делала раньше, но для нас этой раз.**
Итак, если мы решим, что тест умного ученика слишком сложен для копирования, мы можем попробовать скопировать способ, которым он готовился к тестам.

Вот что мы знаем. Создать компьютер, мощность которого равна мозгу, возможно — доказательство этого — наш собственный мозг, эволюционировавший. И если мозг слишком сложен для нас, мы можем попытаться смоделировать эволюцию вместо него. Факт в том, что даже если мы сможем смоделировать мозг, это будет похоже на попытку построить самолёт, копируя движения крыльев птицы — часто машины лучше проектируются с использованием нового, машинного подхода, а не точного копирования биологии.

Как мы можем смоделировать эволюцию, чтобы создать АГИ? Метод, называемый «генетическими алгоритмами», будет работать примерно так: будет происходить процесс оценки и выполнения, который будет повторяться снова и снова (так же, как живые существа «выполняют» свою жизнь, а их «оценивают» по тому, смогли ли они воспроизводиться или нет). Группа компьютеров будет пытаться выполнять задачи, и самые успешные из них будут «скрещиваться», объединяя половину программного обеспечения каждого из них в новый компьютер. Менее успешные будут устранены. С течением многого количества итераций этот процесс естественного отбора будет производить всё более и более совершенные компьютеры. Проблема заключается в создании автоматического цикла оценки и скрещивания, чтобы этот процесс эволюции мог работать самостоятельно.

Недостаток копирования эволюции в том, что эволюция любит заниматься делами в течение миллиардов лет, а мы хотим сделать это за несколько десятилетий.

Но у нас есть много преимуществ перед эволюцией. Во-первых, эволюция не имеет прозрения и работает случайно — она производит больше бесполезных мутаций, чем полезных, но мы контролируем процесс, чтобы он был driven только полезными изменениями и целенаправленными улучшениями. Во-вторых, эволюция не стремится ни к чему, включая интеллект — иногда окружающая среда может даже выбирать против высокого уровня интеллекта (поскольку он требует много энергии). Мы же можем конкретно направлять этот эволюционный процесс на увеличение интеллекта. В-третьих, чтобы выбрать интеллект, эволюция должна инновировать во множестве других способов, чтобы обеспечить интеллект — например, перестраивать способы производства энергии клетками — тогда как мы можем убрать эти дополнительные нагрузки и использовать такие вещи, как электричество. Безусловно, мы будем гораздо, гораздо быстрее, чем эволюция — но неясно, сможем ли мы улучшить эволюцию достаточно, чтобы сделать этот метод жизнеспособным.

**3) Сделать эту всю проблему компьютера, а не нашей.**
Это когда ученые становятся отчаянными и пытаются запрограммировать тест, чтобы он сам себя решал. Но это может быть самый перспективный метод, который у нас есть.

Идея в том, что мы построим компьютер, у которого будут две основные способности: проводить исследования по ИИ и кодировать изменения в себе — позволяя ему не только учиться, но и улучшать свою архитектуру. Мы научим компьютеров быть компьютерными учёными, чтобы они могли самоусовершенствоваться. И это будет их основная работа — находить способы сделать себя умнее. Более подробно об этом позже.

**Всё Это Может Произойти Очень Скоро**
Резкие прогресс в аппаратном обеспечении и инновационные эксперименты с программным обеспечением происходят одновременно, и АГИ может подкрасться к нам быстро и неожиданно по двум основным причинам:

1) Экспоненциальный рост сильный, и то, что кажется медленным развитием, может быстро ускориться — эта GIF отлично иллюстрирует эту концепцию:
![image](https://github.com/user-attachments/assets/081e06ef-59d0-487e-b374-6c04701efef9)

2) Что касается программного обеспечения, прогресс может казаться медленным, но внезапное прозрение может мгновенно изменить темп развития (как, например, в случае с наукой, которая столкнулась с трудностями в понимании устройства Вселенной, пока не открыла, что она гелиоцентрична, и тогда всё стало гораздо проще). Или, когда речь идет о компьютере, способном улучшать сам себя, мы можем казаться далеко, но на самом деле находиться всего в одном изменении системы от того, чтобы он стал в 1000 раз эффективнее и стремительно приблизился к человеческому уровню интеллекта.

# Путь от AGI к ASI
В какой-то момент мы достигнем АГИ — компьютеров с общим интеллектом, равным человеческому. Просто группа людей и компьютеров, живущих в равенстве.

О, на самом деле совсем не так.

Дело в том, что АГИ с таким же уровнем интеллекта и вычислительной мощностью, как у человека, все равно будет иметь значительные преимущества перед людьми. Например:

## "Железо"

1. Скорость. Нейроны мозга работают максимум на 200 Гц, в то время как современные микропроцессоры (которые значительно медленнее, чем те, которые будут использоваться при достижении АГИ) работают на 2 ГГц, то есть в 10 миллионов раз быстрее наших нейронов. Кроме того, внутренние коммуникации в мозге, которые могут двигаться со скоростью около 120 м/с, ужасно уступают компьютерной способности передавать информацию оптически со скоростью света.
2. Размер и объем памяти. Мозг ограничен размером из-за формы черепа, и его нельзя сделать намного больше, иначе передача сигналов между различными частями мозга заняла бы слишком много времени. Компьютеры же могут быть любого физического размера, что позволяет использовать гораздо больше оборудования, иметь гораздо большую оперативную память (RAM) и долгосрочную память (жесткий диск), которая имеет гораздо большую емкость и точность, чем у нас.
3. Надежность и прочность. Не только память компьютера будет более точной. Транзисторы компьютера точнее биологических нейронов и реже подвержены деградации (и их можно починить или заменить, если это необходимо). Человеческие мозги быстро устают, в то время как компьютеры могут работать круглосуточно, без перерывов, на пиковой производительности.

## ПО

1. Редактируемость, обновляемость и широта возможностей. В отличие от человеческого мозга, программное обеспечение компьютера может получать обновления и исправления, его легко экспериментировать. Обновления также могут распространяться на области, где у человеческого мозга слабые стороны. Программное обеспечение человеческого зрения чрезвычайно продвинуто, в то время как его инженерная способность довольно низкая. Компьютеры смогут совместить человеческое зрение с одинаковой оптимизацией в инженерии и любом другом направлении.
2. Коллективная способность. Люди превосходят все другие виды в создании масштабной коллективной интеллектуальной системы. Начиная с развития языка и формирования больших плотных сообществ, продолжая изобретением письма и печати, и сейчас усиливаясь через такие инструменты, как интернет, коллективный интеллект человека — одна из главных причин, по которой мы оказались так далеко от других видов. И компьютеры будут лучше этого делать, чем мы. Мировая сеть ИИ, выполняющая определенную программу, может регулярно синхронизироваться, так что любое знание, полученное одним компьютером, будет мгновенно загружено во все остальные. Группа также сможет действовать как единое целое, потому что не обязательно будут разногласия, мотивации и личные интересы, как у нас среди населения[^11].

ИИ, который, вероятно, достигнет АГИ благодаря программированию для самосовершенствования, не будет воспринимать «человеческий уровень интеллекта» как важную цель — это лишь значимый ориентир с нашей точки зрения — и не будет иметь никакой причины «останавливаться» на нашем уровне. Учитывая преимущества, которые даже АГИ, эквивалентный человеческому интеллекту, будет иметь над нами, очевидно, что он пройдет через человеческий уровень интеллекта всего на миг, прежде чем устремится в область сверхчеловеческого интеллекта.

Это может шокировать нас, когда это произойдет. Причина в том, что с нашей точки зрения: A) хотя интеллект разных животных различен, основное, что мы знаем об интеллекте любого животного, — это то, что он намного ниже нашего, и B) мы воспринимаем самых умных людей как НАМНОГО умнее самых глупых. Примерно так:

![image](https://github.com/user-attachments/assets/863c45be-2294-4a32-bba8-5733c7bae478)

Итак, когда ИИ стремительно повышает свой интеллект в сторону нас, мы будем воспринимать это как будто животное становится умнее. Затем, когда оно достигнет самого низкого уровня человеческого интеллекта — Ник Бостром использует термин «деревенщина» — мы скажем: «Ой, как мило, оно похоже на глупого человека!» Единственная проблема в том, что в огромной шкале интеллекта все люди, от деревенщины до Эйнштейна, находятся в очень узком диапазоне — поэтому, как только ИИ достигнет уровня дурня из деревни и будет объявлен АГИ, он внезапно станет умнее Эйнштейна, и мы не поймём, что произошло:

![image](https://github.com/user-attachments/assets/81b2b9f3-4986-40ad-b947-d1430f809839)

И что происходит… после этого?

## Интеллектуальный взрыв

Надеюсь, вам понравилось обсуждение "обычного" времени, потому что теперь тема становится необычной и пугающей, и так она будет оставаться до конца. Я хочу сделать паузу, чтобы напомнить вам, что всё, что я собираюсь сказать, — это настоящее, реальная наука и реальные прогнозы будущего от множества самых уважаемых мыслителей и учёных. Просто помните об этом.

Тем не менее, как я уже говорил выше, большинство наших текущих моделей достижения AGI (искусственный общий интеллект) предполагают, что ИИ достигает этой ступени благодаря самосовершенствованию. А когда он достигнет уровня AGI, даже системы, которые формировались и развивались с помощью методов, не включающих самосовершенствование, станут достаточно умными, чтобы начать его использовать, если захотят[^12].

И вот здесь мы подходим к очень интенсивному понятию: **рекурсивное самосовершенствование**. Работает это так:

Искусственный интеллект определённого уровня — допустим, уровень «человеческого деревенского дурачка» — программируется с целью повышения своей собственной интеллектуальной мощности. Как только он это делает, он становится умнее — возможно, теперь он на уровне Эйнштейна. Теперь, работая над улучшением своего интеллекта, он может делать большие скачки. Эти скачки делают его гораздо умнее любого человека, позволяя делать ещё более значительные прорывы. По мере того как эти прорывы становятся больше и происходят быстрее, AGI стремительно поднимается по уровню интеллекта и вскоре достигает суперинтеллектуального уровня ASI (искусственный сверхинтеллект). Это называется **Интеллектуальным взрывом**[^13], и это самый яркий пример Закона Ускоряющегося Возврата.

Существует некоторый спор о том, когда ИИ достигнет уровня человеческого общего интеллекта. Средняя дата, указанная в опросе сотен учёных о том, когда они считают вероятным появление AGI, — 2040 год[^13]. Это всего лишь 25 лет отныне, что не звучит так уж много, пока вы не учтёте, что многие из этих мыслителей полагают, что переход от AGI к ASI произойдёт очень быстро. Вот как это может случиться:

_Десятилетия проходят, прежде чем первая система ИИ достигнет низкого уровня общего интеллекта, но в конце концов это происходит. Компьютер способен понимать окружающий мир так же, как ребёнок четырёх лет. Внезапно, в течение часа после достижения этой вехи, система создаёт великую теорию физики, объединяющую общую теорию относительности и квантовую механику — то, чего никто из людей до сих пор не смог сделать окончательно. Через 90 минут после этого AI становится ASI, в 170 000 раз умнее человека._

Такой уровень сверхинтеллекта — это нечто, что мы вообще не можем осознавать, точно так же, как пчела-бомбардировщик не может понять кейнсианскую экономику. В нашем мире "умный" значит IQ 130, а "глупый" — IQ 85. У нас нет слова для IQ 12 952.

Однако одно мы знаем точно: человек стал доминировать на Земле именно благодаря своему интеллекту. Это значит, что ASI, который мы создадим, станет самым могущественным существом в истории жизни на Земле, и все живые существа, включая людей, будут полностью зависеть от его воли — а это может случиться в ближайшие десятилетия.

Если наш скромный мозг сумел придумать Wi-Fi, то что-то в 100, 1000 или даже миллиард раз умнее нас сможет без труда управлять положением каждой отдельной молекулы в мире в любой момент времени. Каждое наше представление о чуде, каждая власть, которую мы себе воображаем у божественного Бога, станет для ASI обыденной деятельностью, такой же простой, как включение лампочки для нас. Создание технологий, способных обратить вспять старение человека, избавить от болезней, голода и даже смерти, перепрограммирование погоды для защиты будущего жизни на Земле — всё это вдруг становится возможным. Возможным также становится немедленный конец всей жизни на Земле. Для нас, если ASI появится, на Земле внезапно возникнет всемогущий Бог — и единственным важным вопросом для нас будет:

### Будет ли он добрым Богом?

---








[^1]: Несущественное примечание в оригинале, я опущу
[^2]: Kurzweil, *The Singularity is Near*, стр. 39
[^3]: Kurzweil, *The Singularity is Near*, стр. 84
[^4]: Курцвейл указывает, что его современный телефон — примерно в миллион раз меньше, в миллион раз дешевле и в тысячу раз мощнее, чем его компьютер в MIT 40 лет назад. Удачи в попытке представить, до чего может довести **сравнимый** скачок в будущем — не говоря уже о **гораздо более экстремальном**, ведь прогресс растёт экспоненциально.
[^5]: Vardi, *Artificial Intelligence: Past and Future*, стр. 5  
[^6]: Kurzweil, *The Singularity is Near*, стр. 84
[^7]: Bostrom, *Superintelligence: Paths, Dangers, Strategies*, loc. 597
[^8]: Nilsson, *The Quest for Artificial Intelligence: A History of Ideas and Achievements*, стр. 318
[^9]: Pinker, How the Mind Works, 36.
[^10]: Kurzweil, *The Singularity is Near*, стр. 118
[^11]: Bostrom, Superintelligence: Paths, Dangers, Strategies, loc. 1500-1576.
[^12]: Подробнее, что такое для компьютера "хотеть", в части 2
[^13]: Это понятие впервые было использовано одним из великих мыслителей в области искусственного интеллекта, Ирвингом Джоном Гудом, в 1965 году.
[^14]: Nick Bostrom, Superintelligence: Paths, Dangers, Strategies, loc. 660


